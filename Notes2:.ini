What we know:
✅ All pairs same size (undistort → resize back)
✅ Single camera body (2048×1366 mainly)
✅ Pure barrel distortion (center = JPEG noise only)
✅ Multiple lenses = varying k1/k2 per image
✅ Tall group = same distortion type, different sensor
✅ Portraits exist, need rotation before processing
✅ 7 identical pairs to remove
✅ 40 near-identical to down-weight
✅ 6 heavy distortion to up-weight
✅ One model handles everything
What we are still missing:
❌ Actual k1/k2 values — not extracted yet
   This is the CORE label for training
   Everything so far was understanding the data
   The actual work starts now

❌ K1/k2 distribution across full 23k
   We don't know the range yet
   Is it tight (-0.1 to -0.3)?
   Or wide (-0.05 to -0.5)?
   This determines model difficulty

❌ Whether focal length assumption (f=max(w,h)) is correct
   Will reveal itself during k1/k2 extraction
   If fit errors are high → f assumption is wrong

❌ Full 23k cleaning results
   We only ran on 994 sample
   Need full counts before extraction



During training, your model makes a prediction.
It gets penalized for being wrong.
That penalty is the LOSS.

Weight = how loud that penalty is.

weight = 1.0 → normal volume
weight = 5.0 → 5x louder, model pays much more attention
weight = 0.3 → 3x quieter, model mostly ignores this
weight = 0.0 → silent, model never learns from this

**Concretely for your categories:**
```
Identical pairs (weight=0.0):
─────────────────────────────
  overall_diff < 0.5
  True k1 ≈ 0 (no distortion)
  
  If you include these:
    Model sees distorted-looking image → label says k1=0
    But similar looking images in dataset have k1=-0.25
    CONTRADICTION → model gets confused
    Predictions pulled toward zero for everything
  
  weight=0.0 means: skip entirely, never backpropagate
  Model never sees this example
  Clean solution

────────────────────────────────────────────────────────

Mild distortion (weight=0.3):
─────────────────────────────
  overall_diff 0.5-2.0
  True k1 ≈ -0.02 to -0.05
  
  Problem: JPEG noise (5px) >> geometric signal (1px)
  The k1/k2 you extract from these will be NOISY
  Like trying to measure 1mm with a ruler marked in cm
  
  If weight=1.0:
    Model trains hard on noisy labels
    Learns wrong patterns from the noise
    Hurts accuracy on normal images
    
  weight=0.3 means: I hear you but I don't trust you much
  Model learns mild cases exist
  But doesn't overfit to their noisy labels
  
────────────────────────────────────────────────────────

Normal distortion (weight=1.0):
────────────────────────────────
  overall_diff 2.0-20.0
  True k1 ≈ -0.1 to -0.35
  Clean labels, reliable extraction
  Vast majority of data
  
  weight=1.0 means: standard, trust these fully
  This is the backbone of training

────────────────────────────────────────────────────────

Heavy distortion (weight=5.0):
────────────────────────────────
  overall_diff > 20.0
  True k1 ≈ -0.35 to -0.5
  Only ~420 in 23k dataset (1.8%)
  
  Without weight boost:
    Model sees these 50x less than normal
    Never really learns strong barrel correction
    Gets test images with wide-angle lens → predicts k1=-0.15
    Result: still visibly distorted → bad score
    
  weight=5.0 means: this example counts as 5 normal examples
  Model sees it effectively 5x more often in gradient updates
  Learns strong barrel correction properly
  
  Also: labels are MOST reliable here
  Large signal >> JPEG noise
  Geometry very clear and unambiguous
```



=======================================================
FULL DATASET CLEANING SUMMARY
=======================================================

Total pairs:          23,118
Corrupted files:      0

Orientation (valid only):
  Landscape:          22,867
  Portrait:           251

Height groups:
  Main  (1342-1380):  22,833
  Tall  (>1380):      284

Categories:
  identical   :    134 (  0.6%)  weight=0.0
  mild        :    699 (  3.0%)  weight=0.3
  normal      : 22,138 ( 95.8%)  weight=1.0
  heavy       :    147 (  0.6%)  weight=5.0

FINAL TRAINING SET:   22,984 images
REMOVED:              134 images

Suspicious barrel ratio (<1.2): 2,386
  These may have non-barrel corrections
  Consider reviewing before k1/k2 extraction

Less barrel ratio means the corner diff 
by the center diff is almost very near; 
that means it is not a barrel problem.




==================================================
SHIFT ANALYSIS RESULTS
==================================================

Total suspicious analyzed: 2,386
Has significant shift (>2px): 651 (27.3%)
No significant shift (<2px):  1,735 (72.7%)

Shift magnitude distribution:
  <2px  (no shift):    1,735
  2-5px (tiny):        207
  5-15px (moderate):   371
  15-30px (large):     44
  >30px (massive):     29

Max shift:    130.4 px
Mean shift:   2.9 px
Median shift: 0.3 px

Property-level analysis:
  Unique properties in suspicious: 1,657
  Properties where ALL images shifted:  319
  Properties where SOME images shifted: 180
  Properties where NO images shifted:   1,158

  